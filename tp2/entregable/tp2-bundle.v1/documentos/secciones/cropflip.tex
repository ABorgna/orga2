\section{Cropflip}

\subsection{Descripción}
La imagen destino del filtro consiste en invertir verticalmente (flip) un recorte (crop) de la imagen fuente a partir de offsets dados como parámetro. El ancho y alto en píxeles de la imagen destino también se pasa como parámetros.
La descripción matemática está dada por la fórmula:

$$ O_{i,\ j}^{k}=I_{tamy+offsety-i-1, \ \ offsetx+j}^{k} $$

Donde el 'crop' de la imagen input corresponde con los píxeles del tipo:

$$
I_{offsety+i, \ \ offsetx+j}^{k} 
\qquad \text{con} \quad 0 \leq i < tamy \ \ \ 0 \leq j < tamx 
$$

\begin{table}[h]
\centering
\mem
\begin{tabular}{l|c|c|c|c|c|c|l}
 & \multicolumn{1}{l|}{}      & \multicolumn{1}{l|}{}       & \multicolumn{1}{l|}{}       & \multicolumn{1}{l|}{}       & \multicolumn{1}{l|}{}       & \multicolumn{1}{l|}{}      &  \\ \hline
 & \cellcolor[HTML]{FFCB2F}$I_{30}$ & \cellcolor[HTML]{FFCB2F}$I_{31}$  & \cellcolor[HTML]{FD6864}$I_{32}$  & \cellcolor[HTML]{FD6864}$I_{33}$  & \cellcolor[HTML]{FD6864}$I_{34}$  & \cellcolor[HTML]{FD6864}$I_{35}$ &  \\ \hline
 & \cellcolor[HTML]{FFCB2F}$I_{24}$ & \cellcolor[HTML]{FFCB2F}$I_{25}$  & \cellcolor[HTML]{FD6864}$I_{26}$  & \cellcolor[HTML]{FD6864}$I_{27}$  & \cellcolor[HTML]{FD6864}$I_{28}$  & \cellcolor[HTML]{FD6864}$I_{29}$ &  \\ \hline
 & \cellcolor[HTML]{FFCB2F}$I_{18}$ & \cellcolor[HTML]{FFCB2F}$I_{19}$ & \cellcolor[HTML]{FD6864}$I_{20}$ & \cellcolor[HTML]{FD6864}$I_{21}$ & \cellcolor[HTML]{FD6864}$I_{22}$  & \cellcolor[HTML]{FD6864}$I_{23}$ &  \\ \hline
 & \cellcolor[HTML]{FFCB2F}$I_{12}$ & \cellcolor[HTML]{FFCB2F}$I_{13}$ & \cellcolor[HTML]{FD6864}$I_{14}$ & \cellcolor[HTML]{FD6864}$I_{15}$ & \cellcolor[HTML]{FD6864}$I_{16}$  & \cellcolor[HTML]{FD6864}$I_{17}$ &  \\ \hline
 & \cellcolor[HTML]{FFCB2F}$I_{6}$ & \cellcolor[HTML]{FFCB2F}$I_{7}$ & \cellcolor[HTML]{FFCB2F}$I_{8}$ & \cellcolor[HTML]{FFCB2F}$I_{9}$ & \cellcolor[HTML]{FFCB2F}$I_{10}$  & \cellcolor[HTML]{FFCB2F}$I_{11}$ &  \\ \hline
 & \cellcolor[HTML]{FFCB2F}$I_{0}$ & \cellcolor[HTML]{FFCB2F}$I_{1}$ & \cellcolor[HTML]{FFCB2F}$I_{2}$ & \cellcolor[HTML]{FFCB2F}$I_{3}$ & \cellcolor[HTML]{FFCB2F}$I_{4}$  & \cellcolor[HTML]{FFCB2F}$I_{5}$ &  \\ \hline
 & \multicolumn{1}{l|}{}      & \multicolumn{1}{l|}{}       & \multicolumn{1}{l|}{}       & \multicolumn{1}{l|}{}       & \multicolumn{1}{l|}{}       & \multicolumn{1}{l|}{}      &
\end{tabular}
\caption{Ilustración de la imagen fuente en memoria. En rojo los píxeles del crop \newline
(offsetx = 2, offsety = 2, tamx = 4, tamy = 4)}
\end{table}

\begin{table}[h]
\centering
\mem
\begin{tabular}{l|c|c|c|c|l}
& \multicolumn{1}{l|}{}       & \multicolumn{1}{l|}{}   & \multicolumn{1}{l|}{}     & \multicolumn{1}{l|}{}      &  \\ \hline
 & \cellcolor[HTML]{FD6864}$I_{14}$ & \cellcolor[HTML]{FD6864}$I_{15}$ & \cellcolor[HTML]{FD6864}$I_{16}$  & \cellcolor[HTML]{FD6864}$I_{17}$ &  \\ \hline
 & \cellcolor[HTML]{FD6864}$I_{20}$ & \cellcolor[HTML]{FD6864}$I_{21}$ & \cellcolor[HTML]{FD6864}$I_{22}$  & \cellcolor[HTML]{FD6864}$I_{23}$ &  \\ \hline 
 & \cellcolor[HTML]{FD6864}$I_{26}$  & \cellcolor[HTML]{FD6864}$I_{27}$  & \cellcolor[HTML]{FD6864}$I_{28}$  & \cellcolor[HTML]{FD6864}$I_{29}$ &  \\ \hline
  & \cellcolor[HTML]{FD6864}$I_{32}$ & \cellcolor[HTML]{FD6864}$I_{33}$  & \cellcolor[HTML]{FD6864}$I_{34}$  & \cellcolor[HTML]{FD6864}$I_{35}$ &  \\ \hline
  & \multicolumn{1}{l|}{}       & \multicolumn{1}{l|}{}  & \multicolumn{1}{l|}{}      & \multicolumn{1}{l|}{}      &
\end{tabular}
\caption{Ilustración de la imagen destino en memoria}
\end{table}




No es difícil notar que las filas del crop en la fuente no constituyen una tira contigua de píxeles en memoria, si no que se encuentran distanciadas por el tamaño en bytes de offsetx lo que implica que necesitaremos iterar en dos ciclos anidados para poder procesar el crop.

\subsection{Implementaciones}
Al no involucrar operaciones aritméticas entre componentes de la imagen, las implementaciones del filtro se centran en accesos a memoria. Por lo tanto, las implementaciones solamente difieren en el modo en que se copian y asignan píxeles a la imagen output, radicando en esos métodos nuestro foco de análisis. 
\subsubsection{Implementaciones C y SSE}
La implementación C simplemente se trata de recorrer la imagen con una sola variable aplicando pixel a pixel la transformación dada por la fórmula matemática previamente mencionada. Mientras que la implementación correspondiente a SSE recorre la imagen fuente desde la fila superior del recuadro ($I_{32}$ en el cuadro 1) del crop hacia abajo de a 4 píxeles por iteración como indica el siguiente pseudo-código: 


\begin{codesnippet}
\begin{verbatim}

temp = src + offsetx*4 +srcRowSize*(offsety+tamy-1)       
{Apunta al primer píxel de la esquina superior izq. del crop}
for i = 0 to tamy:  
--> for j = 0 to tamx:  
-----> xmm0 = [temp]
-----> [dst] = xmm0 
-----> dst = dst  + 16 
-----> temp =  temp + 16 
-----> temp = temp - (dstRowSize + srcRowSize)       
{Decrece el ancho de la imagen destino y el de la fuente para apuntar primer pixel de la fila de
abajo a la que procesó}    
--> end for 
end for 

\end{verbatim}
\end{codesnippet}



De esta manera, las lecturas y escrituras en memoria representan $\frac{1}{16} = 0,0625 =  6,25\%$ del total de los accesos a memoria de la implementación C.


\subsubsection{Implementaciones SIMD paralelo en 128 y 256 bits}
Se diferencian de la implementación anterior de SSE en el uso de la mayor cantidad posible de registros \xmm{} (\ymm{} de 256 bits en el caso de las implementaciones de AVX) para las operaciones de transferencia de bloques de píxeles de la imagen fuente a la destino. 
\\

Dado que las lecturas y escrituras en memoria de cada registro son independientes entre sí, la ejecución fuera de orden del procesador hace que la transferencia por bloque sea más rápida que la implementación individual (que recorre la imagen con un único registro \xmm{}). Por cuestiones de vecindad espacial de los píxeles en la memoria, los accesos a memoria de cada registro tienen chances particularmente altas de hit en caché, no demorando así las lecturas del resto de los registros.
\\

Recordando que los registros de AVX tienen 32 bytes de capacidad y cada pixel en nuestro formato ocupa 4 bytes, cada registro \ymm{} tendrá capacidad para:

$$ \frac{32 \ bytes}{4 \ \frac{bytes}{px}} = 8 \ px $$

Por lo cual, suponiendo $ tamx \equiv 0 \ (mod \ 8) $ (como es el caso de una imagen de salida de 512x512), tendríamos $\frac{1}{32} = 0,03125 =  3,125\%$ del total de accesos a memoria de la implementación en C.

\subsubsection{Copiado paralelo de vectores}
\label{explicacionCopyN}

La asignación de píxeles se hace llamando a las funciones externas 'copyN_sse' y 'copyN_avx2'\footnote{../entregable/tp2-bundle.v1/codigo/lib} que copian tiras de píxeles de una imagen a otra por bloques de 64/4/1 ó 128/8/1 píxeles (sse y avx2 respectivamente) según sea posible en cada iteración. A modo de ejemplo (los otros casos son análogos), para copiar bloques de 64px (256B) desde la posición indicada por rsi a la indicada por rdi se cargan los valores correspondientes de la siguiente manera:
\newline
\\
\xmm{0} $\leftarrow$ {[rsi]} \\
\xmm{1} $\leftarrow$ {[rsi+16]} \\
... \\
\xmm{14} $\leftarrow$ {[rsi+224]}  \\
\xmm{15} $\leftarrow$ {[rsi+240]} \\
\\
{[rdi]} $\leftarrow$ \xmm{0} \\
{[rdi+16]} $\leftarrow$ \xmm{1} \\
... \\
{[rdi+224]} $\leftarrow$ \xmm{14} \\
{[rdi+240]} $\leftarrow$ \xmm{15} \\

Esta técnica de aplicar por cada iteración operaciones que, comúnmente, se harían en varias se conoce como 'loop unrolling'. Como desventaja frente a la optimización por paralelismo y minimización branch mispredictions, en códigos de mucho mayor tamaño podría aumentar tan significativamente el tamaño del binario que aumente fuertemente el número de 'cache misses'. En nuestro caso copyN.o (que incluye a 'copyN_sse' y 'copyN_avx2') pesa 3,3 kB y es bastante probable que entre enteramente en caché.
\\

En el caso del filtro Cropflip, las tiras de píxeles corresponden a tiras de tamaño 'tamx' (es decir, al ancho del crop).  


\subsection{Experimentos - Rendimiento y análisis}

\subsubsection{Comparación entre implementaciones}

\cuidado \\
1. No queda claro cual es la definicion de 'speedup' que usan. Un speedup de 0.4x es que tardo un 40\% menos de ciclos o que? Tampoco queda claro que usan como parametro de normalización. \\
2. Sospechosamente, muchas barras dan exacto 1x de speedup. Esto es muy raro! \\
3. Las  barras de error tienden a hacerme creer aun mas que hay un error en el grafico \\
4. Si lo que se desea es comparar entre implementaciones, sería mejor que agrupen por sistema en vez de por tipo de implementación. Puesto así parece que el foco fuera comparar entre distintos procesadores, pero eso es secundario. \\
\cuidado

\begin{figure}[h]
\centering
\includegraphics[width=0.90\textwidth]{cropflip-time-speedup} 
\caption{Tiempo de ejecución relativo de implementaciones ASM de cropflip contra la implementación C compilada con -O3}
\label{fig:cropflip-time-speedup}
\end{figure}

A diferencia de los otros dos filtros, donde el procesamiento de imágenes involucra operaciones aritméticas paralelas, la implementación AVX de Cropflip casi no presenta 'speedup' respecto de las implementaciones de SSE con registros de 128 bits en paralelo.

Sí se presentan entre las dos implementaciones de SSE, donde la diferencia es casi del doble a favor de SSE 'paralela'. Dados los parámetros tales que el recuadro de crop mide 128x128px, en la implementación con loop unrolling alcanza con dos iteraciones procesando 64px en cada una para cubrir cada fila. Mientras que para la versión SSE común hay que recorrer: $\frac{128 \ \frac{px}{fila}}{8 \ \frac{px}{iteracion}} = 32 \ \frac{iteraciones}{fila}$ .
\\

Sin embargo, la cantidad de iteraciones no refleja el hecho de que aún en ejecución fuera de orden los accesos a memoria siguen siendo individuales, teniendo que 'resecuencializar' las instrucciones para acceder ordenadamente. Podría suponerse que es debido a esto que el speedup no es del orden de magnitud que sugerirían las respectivas iteraciones por fila.

Como habíamos anticipado al hablar del loop unrolling en SSE, el tamaño del binario no es lo suficientemente grande como para no poder ser cacheado eficientemente. La vecindad espacial de las tiras de píxeles también colaboran para que el hitrate se mantenga alto aún cuando las filas del crop no son contiguas en memoria como comentamos en la descripción.
\\

Es notable como el procesador de AMD es el único que corre mas lento la implementación AVX (comportamiento que no vimos en las implementaciones AVX de otros filtros). Suponemos que puede deberse a un mal rendimiento de la implementación de copia a los registros \ymm{}.

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{cropflip-cycles}
\label{fig:cropflip-cycles}
\caption{Ciclos de clock del timestamp counter durante la ejecución del filtro cropflip}
\end{figure}

\cuidado \\
se_par da speedup de 1x. Sin embargo surge otra cosa que pone en duda los resultados de sse: por que C con -O3, que tampoco hace loop unroling es el doble de rápido? \\
\cuidado

Se observa una diferencia de casi la mitad ciclos de clock entre las versiones de SSE a favor del loop unrolling ('SSE Parelo') donde parecería que, gracias a un buen hitrate, los puntos fuertes  (particularmente paralelismo, no tanto minimizar branch mispredictions como veremos más adelante) destacan a pesar del hecho de que los accesos a memoria son individuales y no pueden solaparse.
\\

Pudimos corrobar que no es casualidad que el rendimiento de la implementación en C@-O3 sea similar al de las implementaciones SSE (particularmente 'SSE paralelo') utilizando GDB para ver el código compilado y comprobando que vectorizaba con operaciones SSE como se muestra a continuación:

\begin{lstlisting}
0x0000000000403995 <cropflip_c+229>: xor    edx,edx
0x0000000000403997 <cropflip_c+231>: movdqu xmm0,XMMWORD PTR [rcx+rax*1]
0x000000000040399c <cropflip_c+236>: add    edx,0x1
0x000000000040399f <cropflip_c+239>: movdqu XMMWORD PTR [rsi+rax*1],xmm0
0x00000000004039a4 <cropflip_c+244>: add    rax,0x10
\end{lstlisting}

\cuidado \\
1. Que version de GCC se usó? probaron en varios sistemas, usaron el mismo GCC en todos? en caso de que no, al menos generó un codigo assembler equivalente? \\
2. Con que flags se compiló? \\
\cuidado

A modo comparativo también incluimos el análisis de rendimiento entre las diversas optimizaciones para la implementación de C.

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{cropflip-c-time}
\label{fig:cropflip-c-time}
\caption{Tiempo de ejecución de la implementación C del filtro cropflip compilada con distintos optimizaciones}
\end{figure}

También es remarcable que el salto en rendimiento se produce entre versiones de ASM y de C con optimización menor a -O3, donde bajan del rango de 20-160 microsegundos para las implementaciones C-O1/C-O2 a 3-8 microsegundos para las de ASM y C-03 (y cercanos al 10 por ciento para los rangos de ciclos de clock).

\cuidado \\
Estaría bueno que relacionen la version -O1/O2 (que seguramente no usa registros xmm) con respecto a -O3 donde los accesos a memoria que eran el 6.25\%. Tambien es interesante el resultado -O0, es ¿20 veces mas lento que O3?
\cuidado

\subsubsection{Caché misses}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{cropflip-cache-map-sse-par-gflan-MS-7817}
\caption{Porcentaje de misses de la cache en función del tamaño durante la ejecución del filtro cropflip, copiando e invirtiendo la imagen entera, en un procesador con 8MB de caché}
\label{fig:cropflip-cache-map-sse_par-gflan-MS-7817}
\end{figure}

\cuidado \\
Los resultados que ponen acá son muy interesantes, pero tienen un problema de presentación: al principio al leer no se entiende bien que es lo que quisieron hacer. Sería mejor que antes de las figuras y conclusiones dedicaran un parrafito a explicar que que se preguntaron, que quisieron medir para responder sus preguntas y cómo hicieron para medirlo.
\cuidado

Observamos que como realizamos las corridas con la caché en caliente y gracias a la vecindad temporal, cuando el tamaño en bytes de la imagen es menor al de la caché el hitrate se mantiene cerca del 100\%. Cuando la imagen ya no entra en caché se termina desplazando a sí misma durante la ejecución y la cantidad de misses sube hasta cerca del 40\%.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{cropflip-time-rel-map-sse-par-gflan-MS-7817}
\caption{Millones de píxeles procesados por segundo en función del tamaño durante la ejecución del filtro cropflip, copiando e invirtiendo la imagen entera, en un procesador con 8MB de caché L3 y 256kB de caché L2 por núcleo}
\label{fig:cropflip-tame-rel-map-sse_par-gflan-MS-7817}
\end{figure}

En esta imagen podemos observar cómo cuando la imagen ya no entra en caché el throughput baja a menos de la mitad, ya que el procesador se queda esperando a la memoria mas de la mitad del tiempo.

También observamos una segunda franja cuando la imagen ocupa menos de 256kB, que corresponde al tamaño de la caché L2. Es interesante ver la diferencia de rendimiento entre ambas caches, ya que podemos procesar el doble de rápido cuando todos los accesos son a L2.

Cuando la imagen tiene poco ancho el procesamiento se ve interrumpido muy seguido por la lógica de cambio de linea, y el rendimiento se ve afectado.

\subsubsection{Observación sobre las predicciones de saltos}

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{cropflip-branch-misses}
\label{fig:cropflip-branch-misses}
\end{figure}

En este gráfico se puede apreciar algo bastante curioso: mientras que para algunos procesadores el loop unrolling minimizó muy efectivamente el porcentaje de branch mispredictions en las implementaciones de AVX y de SSE en paralelo frente a las implementaciones que procesan con un único vector (ya vimos que la implementación en C con optimización O3 también usa un registro XMM para los accesos a memoria), para otros significó un retroceso.

\ Esto resulta particularmente contraintuitivo si tenemos en cuenta que en teoría minimizar iteraciones parecería implicar minimizar predicciones y por lo tanto penalidades. Sin embargo esto se puede deber a que, en cada ciclo, se requiere evaluar si la cantidad restante de píxeles para copiar es mayor a  64/4/1 ó 128/8/1 píxeles para poder saltar a cada subrutina. Resultando así contraproducente desde este punto de vista dicha implementación.

